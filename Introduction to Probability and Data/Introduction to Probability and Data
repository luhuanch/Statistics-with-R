(Week I)Introduction to Data:
	1. Observation, variables and data matrics

	2. Type of variables
		-numerical(quatitative)
			-continuous
			-discrete
		categorical(qualitative)
			ordnial(满意，稍微满意，不满意)
			regular categorical
	3. relationship between variables
		- Two variables that show some connection with one another are called associated(dependent)
		- Association can be further described as positive or negative
		- if two variavle are not associated, they are said to be independent

Sampling and Sources of bias:
	Convenience sample: individuals who are easily accessible are more likely to be included in the sample.
	Non-response: if only a (non-random) fraction of the randomly sampled people respond to a survey such that the sample is no longer respresentative of the population.
	Voluntary reponse: Occurs when the sample consists of people who volunteer yo respond because they have strong opinion on the issue.

Sampling methods:
	simple random sample(SRS): each casee is equally likely to be selected
	cluster sample: divide the population clusters, randomly sample a few clusters, then sample all observations within these clusters. 
	stratified sample: divide the population into homogenous strata, then randomly sample from within each stractum.
	multistage sample: divide the population clusters, randomly sample a few clusters, then randomly sample within these clusters. 

Principles of experimental design:
	1. control: compare treatment of interest to a control group.
	2. randomize: randomly assign subjects to treatments.
	3. replicate: collect a sufficiently large sample, or replicate the entire study.
	4. block: block for variavles known or suspected to affect the outcome. 


(Week II)
一、Exploring Numerical Data:
		Scatterplots:
			-visualizing the relationship between two numerical variables
		Histogram: 
			-provides a view of the data density 
			-especially useful for describing the shape of the data
		Dotplot:
			-useful when individual values are of interest
			-can get busy as the sample size increases
		Box plot:
			-useful for highlighting outliers, median, IQR
	Evaluating the relationship:
		-direction (positive/negative)
		-shape (linear/curved)
		-strength (strong/weak)
		-outliers
	Skewness:
		-left skewed (longer tail is on the left)
		-symmetric
		-right skewed (longer tail is on the right)
	Modality:
		-unimodal
		-bimodal
		-uniform
		-multimodal


Measures of center:
	median: midpoint of the distribution (50 percentile)
	mean: arithmetic average
	mode: most frequent observation


Measures of spread:
	- range: (max-min)
	- variance: roughly the average squared deviation from the mean
		1. why square the differences: 
			-get rid of the negatives so that nagatives and positives do not cancel each other when added together.
			-increase larger deviations more than smaller ones so that they are weighed more heavily
	- standard deviation(square root of variance): roughly the average deviation around the mean, and has the same units as the data.
	- inter quartile range: IQR = Q3 - Q1


Robust Statistics:
	We defined robust statistics as measures on which extreme observations have little effect.
		robust(median/IQR) used for skewed with extreme observations
		non-robust(mean/SD) used for symmetric distributions


Tranforming data:
	- a transformation is a rescaling of the data using a function
	- when data are very strongly skewed, we sometimes transform them so they are easier to model.

	Method:
		(natural) log transformation: 
			-often applied when much of the data cluster near zero(relative to the larger values in the data set) and all observations are positive.
			-to make the relationship between the variables more linear, and hence easier to model with simple methods.
		square root: 
		inverse:

	Goals of transformations:
		- to see the data structure differetly
		- to reduce skew assist in modeling 
		- to straighten a nonlinear relationship in scatterplot


二、 Exploring Categorical Data 
	Frequency table & bar plot:
		-Difference than histograms:
			1. barplots for categorical variables, histograms for numerical variables
			2. x-axis on histogram is a number line, and the ordering of the bars are not interchangeable
	Segmented bar plot:
		- Useful for visualizing conditional frequency distribution
		- compare relative frequencies to explore the relationship between the variables


(Week III) 
一、 Define Probability:
Disjoint Events:	
	Disjoint(mutually exclusive) events cannot happen at the same time. P(A and B) = 0
		- For disjoint events A and B, P(A or B) = P(A) + P(B)
	Non-disjoint events can happen at the same time. P(A and B) 不等于 0
		- For Non-disjoint events A and B, P(A or B) = P(A) + P(B) - P(A and B)


	A probability distribution lists all possible outcomes in the sample space, and the probabilities with which they occur.

Independence:
	Two processes are independet if knowing the outcome of one provides no useful information about the outcome of the other.

	determining dependence based on sample data:
		observe difference between conditional probabilities -> dependence -> hypothesis test


二、 Conditional Probability:
Conditional Probability: P(A|B) = P(A and B)/P(B)
	if P(A|B) = P(A) then the events A and B are said to be independent.
			Conceptually: giving B does not tell us anything about A.
			Mathematically: if events A and B are independent, P(A and B) = P(A) * P(B)


Probability Trees:


Bayesian inference:
	posterior: The probability we just calculated is also called the posterior probability. 




(Week IV)
Normal distribution:
	1.Unimodal and symmetric	
		- bell curve 
	2.Follows very strict guildlines about how variably the data are distributed around the mean.
	3.Many variables are nearly normal, but none are exactly normal

68 - 95 - 99.7% rule 

Standardizing with Z scores:
	-standardized (Z) score of an observation is the number of standard deviations it falls above or below the mean. 
		Z = (observation - mean)/Standard Deviation
	-Z score of mean  = 0
	-unusual observation: |Z| > 2
	-defined for distribution of any shape

percentile:
	1. When the distribution is normal, Z scores can be used to calculate percentiles
	2. Percentile is the percentage of observations that fall below a given data point
	3. Graphically, percentile is the area below the probablity distribution curve to the left of that observation
	R Code:
		> pnorm(-1, mean = 0, sd = 1)    -------pnorm for probablity
		> qnorm(0.90, mean = 1500, sd = 300)    --------qnorm for quantiles

------------------------------
Binomial Distribution:
	The binomial distribution describes the probability of having exactly k successes in n independent Bernouilli trials with probability of success p.
		number of scenarios * p(single scenario) = (n!/(k!(n-k)!)*(p^k)(1-p)^(n-k)

		R Code for choosing 2 success out of 9:
			choose(9,2)
	Bernouilli Random Variables: 
		when an individual trial has only two possible outcomes called Bernouilli Random Variables


	Binomial Conditions:
		1. the trials must be independent
		2. the number of trials, n, must be fixed
		3. each trial outcome must be classified as a success or a failure
		4. the probability of success, p, must be the same for eacg trial

	R code:
		dbinom(8, size = 10, p = 0.13) 10个里面选8个成功的，单个成功概率是0.13

	********
	Expected Value(mean) of binomial distribution = np
	Standard Deviation of binomial distribution = sqrt(np(1-p))